#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é—®é¢˜2ï¼šåŸºäºKMeansèšç±»çš„BMI+å­•å‘¨äºŒç»´èšç±»åˆ†æ
ç›®æ ‡ï¼šä½¿ç”¨è‚˜éƒ¨æ³•ç¡®å®šæœ€ä½³èšç±»æ•°(K=3-5)ï¼Œæ¶ˆé™¤ä¸»è§‚æ€§ï¼Œè¾“å‡ºæ¯ç»„BMIåŒºé—´å’Œæœ€ä½³æ£€æµ‹æ—¶ç‚¹
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾è¡¨æ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

print("é—®é¢˜2ï¼šåŸºäºKMeansèšç±»çš„BMI+å­•å‘¨äºŒç»´èšç±»åˆ†æ")
print("=" * 80)

# ==================== æ•°æ®è¯»å–ä¸é¢„å¤„ç† ====================
print("\n1. æ•°æ®è¯»å–ä¸é¢„å¤„ç†")
print("-" * 50)

# è¯»å–ç”·èƒæ•°æ®ï¼ˆå¤„ç†ç¼–ç é—®é¢˜ï¼‰
try:
    df = pd.read_csv("../new_data/boy/boy_cleaned.csv", encoding='utf-8')
except UnicodeDecodeError:
    try:
        df = pd.read_csv("../new_data/boy/boy_cleaned.csv", encoding='gbk')
    except UnicodeDecodeError:
        df = pd.read_csv("../new_data/boy/boy_cleaned.csv", encoding='latin-1')

print(f"âœ“ æ•°æ®è¯»å–å®Œæˆ: {df.shape[0]} æ¡è®°å½•ï¼Œ{df['å­•å¦‡ä»£ç '].nunique()} ä¸ªå­•å¦‡")

# æ£€æŸ¥å¿…è¦åˆ—
required_cols = ['å­•å¦‡ä»£ç ', 'YæŸ“è‰²ä½“æµ“åº¦', 'å­•å‘¨_æ•°å€¼', 'å­•å¦‡BMI']
missing_cols = [col for col in required_cols if col not in df.columns]
if missing_cols:
    print(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
    exit()

# æ•°æ®æ¸…æ´—
df_clean = df[required_cols + ['å¹´é¾„']].dropna()
print(f"âœ“ æ¸…æ´—åæ•°æ®: {df_clean.shape[0]} æ¡è®°å½•")

# ==================== è¾¾æ ‡æ—¶é—´è®¡ç®— ====================
print("\n2. è¾¾æ ‡æ—¶é—´è®¡ç®—")
print("-" * 50)

def calculate_target_time(group):
    """è®¡ç®—YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ—¶é—´ï¼ˆé¦–æ¬¡â‰¥4%ï¼‰"""
    # æŒ‰å­•å‘¨æ’åº
    group_sorted = group.sort_values('å­•å‘¨_æ•°å€¼')
    
    # æ‰¾åˆ°é¦–æ¬¡è¾¾æ ‡çš„è®°å½•
    target_records = group_sorted[group_sorted['YæŸ“è‰²ä½“æµ“åº¦'] >= 0.04]
    
    if len(target_records) > 0:
        return target_records.iloc[0]['å­•å‘¨_æ•°å€¼']
    else:
        # å¦‚æœæœªè¾¾æ ‡ï¼Œä½¿ç”¨æœ€åä¸€æ¬¡æ£€æµ‹çš„å­•å‘¨
        return group_sorted.iloc[-1]['å­•å‘¨_æ•°å€¼']

# è®¡ç®—æ¯ä¸ªå­•å¦‡çš„åŸºæœ¬ä¿¡æ¯
patient_basic_info = df_clean.groupby('å­•å¦‡ä»£ç ').agg({
    'å­•å¦‡BMI': 'first',  # BMIå–ç¬¬ä¸€ä¸ªå€¼ï¼ˆé€šå¸¸ä¸å˜ï¼‰
    'YæŸ“è‰²ä½“æµ“åº¦': 'max',  # æœ€é«˜Yæµ“åº¦
    'å­•å‘¨_æ•°å€¼': 'mean',  # å¹³å‡å­•å‘¨
    'å¹´é¾„': 'first'
}).round(3)

# è®¡ç®—è¾¾æ ‡æ—¶é—´
target_times = df_clean.groupby('å­•å¦‡ä»£ç ', group_keys=False).apply(calculate_target_time)

print(f"âœ“ åŸºæœ¬ä¿¡æ¯è®¡ç®—å®Œæˆ: {len(patient_basic_info)} ä¸ªå­•å¦‡")
print(f"âœ“ è¾¾æ ‡æ—¶é—´è®¡ç®—å®Œæˆ: {len(target_times)} ä¸ªå­•å¦‡")

# æ„å»ºèšç±»åˆ†ææ•°æ®é›†
clustering_data = pd.DataFrame({
    'å­•å¦‡ä»£ç ': patient_basic_info.index,
    'BMI': patient_basic_info['å­•å¦‡BMI'].values,
    'è¾¾æ ‡æ—¶é—´': target_times.values,
    'å¹³å‡å­•å‘¨': patient_basic_info['å­•å‘¨_æ•°å€¼'].values,
    'æœ€å¤§Yæµ“åº¦': patient_basic_info['YæŸ“è‰²ä½“æµ“åº¦'].values,
    'å¹´é¾„': patient_basic_info['å¹´é¾„'].values
})

print(f"âœ“ èšç±»æ•°æ®é›†æ„å»ºå®Œæˆ: {len(clustering_data)} ä¸ªå­•å¦‡")
print(f"  BMIèŒƒå›´: [{clustering_data['BMI'].min():.1f}, {clustering_data['BMI'].max():.1f}]")
print(f"  è¾¾æ ‡æ—¶é—´èŒƒå›´: [{clustering_data['è¾¾æ ‡æ—¶é—´'].min():.1f}, {clustering_data['è¾¾æ ‡æ—¶é—´'].max():.1f}]å‘¨")

# ==================== ç‰¹å¾å‡†å¤‡ä¸æ ‡å‡†åŒ– ====================
print("\n3. ç‰¹å¾å‡†å¤‡ä¸æ ‡å‡†åŒ–")
print("-" * 50)

# é€‰æ‹©èšç±»ç‰¹å¾ï¼šBMI + è¾¾æ ‡æ—¶é—´ï¼ˆä½œä¸ºæœ€ä½³æ£€æµ‹æ—¶ç‚¹çš„ä»£ç†ï¼‰
X_features = clustering_data[['BMI', 'è¾¾æ ‡æ—¶é—´']].values
feature_names = ['BMI', 'è¾¾æ ‡æ—¶é—´(å‘¨)']

print(f"âœ“ èšç±»ç‰¹å¾: {feature_names}")
print(f"  ç‰¹å¾ç»Ÿè®¡:")
for i, name in enumerate(feature_names):
    print(f"    {name}: å‡å€¼={X_features[:, i].mean():.2f}, æ ‡å‡†å·®={X_features[:, i].std():.2f}")

# æ ‡å‡†åŒ–ç‰¹å¾
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_features)
print(f"âœ“ ç‰¹å¾æ ‡å‡†åŒ–å®Œæˆ")

# ==================== è‚˜éƒ¨æ³•ç¡®å®šæœ€ä½³èšç±»æ•° ====================
print("\n4. è‚˜éƒ¨æ³•ç¡®å®šæœ€ä½³èšç±»æ•°")
print("-" * 50)

# æµ‹è¯•Kå€¼èŒƒå›´
k_range = range(2, 8)  # æ‰©å±•åˆ°2-7ï¼Œé‡ç‚¹å…³æ³¨3-5
inertias = []
silhouette_scores = []

print("ä¸åŒKå€¼çš„èšç±»æ•ˆæœè¯„ä¼°:")
for k in k_range:
    # KMeansèšç±»
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X_scaled)
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    inertia = kmeans.inertia_
    silhouette_avg = silhouette_score(X_scaled, labels)
    
    inertias.append(inertia)
    silhouette_scores.append(silhouette_avg)
    
    print(f"  K={k}: æƒ¯æ€§={inertia:.2f}, è½®å»“ç³»æ•°={silhouette_avg:.3f}")

# è®¡ç®—è‚˜éƒ¨ç‚¹ï¼ˆæƒ¯æ€§ä¸‹é™ç‡çš„å˜åŒ–ç‚¹ï¼‰
def find_elbow_point(inertias):
    """æ‰¾åˆ°è‚˜éƒ¨ç‚¹"""
    # è®¡ç®—ä¸€é˜¶å·®åˆ†ï¼ˆä¸‹é™ç‡ï¼‰
    first_diff = np.diff(inertias)
    # è®¡ç®—äºŒé˜¶å·®åˆ†ï¼ˆä¸‹é™ç‡çš„å˜åŒ–ï¼‰
    second_diff = np.diff(first_diff)
    # è‚˜éƒ¨ç‚¹æ˜¯äºŒé˜¶å·®åˆ†æœ€å¤§çš„ç‚¹
    elbow_idx = np.argmax(second_diff) + 2  # +2å› ä¸ºä¸¤æ¬¡diffæ“ä½œ
    return elbow_idx

elbow_k = find_elbow_point(inertias)
optimal_k_silhouette = k_range[np.argmax(silhouette_scores)]

print(f"\nè‚˜éƒ¨æ³•åˆ†æç»“æœ:")
print(f"  è‚˜éƒ¨ç‚¹Kå€¼: {elbow_k}")
print(f"  è½®å»“ç³»æ•°æœ€ä¼˜Kå€¼: {optimal_k_silhouette}")

# é€‰æ‹©æœ€ç»ˆKå€¼ï¼ˆä¼˜å…ˆè€ƒè™‘3-5èŒƒå›´å†…çš„æœ€ä¼˜å€¼ï¼‰
candidates = []
for k in [3, 4, 5]:
    if k in k_range:
        idx = list(k_range).index(k)
        candidates.append((k, silhouette_scores[idx]))

if candidates:
    optimal_k = max(candidates, key=lambda x: x[1])[0]
    print(f"  âœ“ æœ€ç»ˆé€‰æ‹©Kå€¼: {optimal_k} (åœ¨3-5èŒƒå›´å†…è½®å»“ç³»æ•°æœ€ä¼˜)")
else:
    optimal_k = optimal_k_silhouette
    print(f"  âœ“ æœ€ç»ˆé€‰æ‹©Kå€¼: {optimal_k}")

# ==================== æ‰§è¡Œæœ€ä¼˜èšç±» ====================
print("\n5. æ‰§è¡Œæœ€ä¼˜èšç±»åˆ†æ")
print("-" * 50)

# ä½¿ç”¨æœ€ä¼˜Kå€¼è¿›è¡Œèšç±»
kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
final_labels = kmeans_final.fit_predict(X_scaled)

# æ·»åŠ èšç±»æ ‡ç­¾åˆ°æ•°æ®
clustering_data['èšç±»æ ‡ç­¾'] = final_labels

print(f"âœ“ æœ€ç»ˆèšç±»å®Œæˆ (K={optimal_k})")
print(f"  è½®å»“ç³»æ•°: {silhouette_score(X_scaled, final_labels):.3f}")

# ==================== èšç±»ç»“æœåˆ†æ ====================
print("\n6. èšç±»ç»“æœåˆ†æ")
print("-" * 50)

cluster_results = []
print("å„èšç±»ç»„è¯¦ç»†åˆ†æ:")

for cluster_id in range(optimal_k):
    cluster_data = clustering_data[clustering_data['èšç±»æ ‡ç­¾'] == cluster_id]
    
    # åŸºæœ¬ç»Ÿè®¡
    n_patients = len(cluster_data)
    bmi_min = cluster_data['BMI'].min()
    bmi_max = cluster_data['BMI'].max()
    bmi_mean = cluster_data['BMI'].mean()
    
    # æœ€ä½³æ£€æµ‹æ—¶ç‚¹ï¼ˆè¾¾æ ‡æ—¶é—´çš„å¹³å‡å€¼ï¼‰
    optimal_timepoint = cluster_data['è¾¾æ ‡æ—¶é—´'].mean()
    timepoint_std = cluster_data['è¾¾æ ‡æ—¶é—´'].std()
    
    # å…¶ä»–ç‰¹å¾
    age_mean = cluster_data['å¹´é¾„'].mean()
    max_y_conc = cluster_data['æœ€å¤§Yæµ“åº¦'].mean()
    
    cluster_results.append({
        'èšç±»ç»„': f'ç»„{cluster_id}',
        'æ ·æœ¬æ•°': n_patients,
        'BMIèŒƒå›´': f'[{bmi_min:.1f}, {bmi_max:.1f}]',
        'å¹³å‡BMI': bmi_mean,
        'æœ€ä½³æ£€æµ‹æ—¶ç‚¹': optimal_timepoint,
        'æ—¶ç‚¹æ ‡å‡†å·®': timepoint_std,
        'å¹³å‡å¹´é¾„': age_mean,
        'å¹³å‡æœ€å¤§Yæµ“åº¦': max_y_conc
    })
    
    print(f"\n  ç»„{cluster_id} ({n_patients}äºº):")
    print(f"    BMIåŒºé—´: [{bmi_min:.1f}, {bmi_max:.1f}] (å‡å€¼: {bmi_mean:.1f})")
    print(f"    æœ€ä½³æ£€æµ‹æ—¶ç‚¹: {optimal_timepoint:.1f}Â±{timepoint_std:.1f}å‘¨")
    print(f"    å¹³å‡å¹´é¾„: {age_mean:.1f}å²")
    print(f"    å¹³å‡æœ€å¤§Yæµ“åº¦: {max_y_conc:.3f} ({max_y_conc*100:.1f}%)")

# ==================== ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ ====================
print("\n7. ç»„é—´å·®å¼‚æ˜¾è‘—æ€§æ£€éªŒ")
print("-" * 50)

# BMIç»„é—´å·®å¼‚æ£€éªŒ
bmi_groups = [clustering_data[clustering_data['èšç±»æ ‡ç­¾'] == i]['BMI'].values 
              for i in range(optimal_k)]
f_stat_bmi, p_val_bmi = stats.f_oneway(*bmi_groups)

# è¾¾æ ‡æ—¶é—´ç»„é—´å·®å¼‚æ£€éªŒ  
time_groups = [clustering_data[clustering_data['èšç±»æ ‡ç­¾'] == i]['è¾¾æ ‡æ—¶é—´'].values 
               for i in range(optimal_k)]
f_stat_time, p_val_time = stats.f_oneway(*time_groups)

print(f"ç»„é—´BMIå·®å¼‚æ£€éªŒ: F={f_stat_bmi:.3f}, p={p_val_bmi:.6f}")
print(f"ç»„é—´è¾¾æ ‡æ—¶é—´å·®å¼‚æ£€éªŒ: F={f_stat_time:.3f}, p={p_val_time:.6f}")

if p_val_bmi < 0.05:
    print("âœ“ å„ç»„BMIå­˜åœ¨æ˜¾è‘—å·®å¼‚")
else:
    print("âš ï¸ å„ç»„BMIå·®å¼‚ä¸æ˜¾è‘—")

if p_val_time < 0.05:
    print("âœ“ å„ç»„æœ€ä½³æ£€æµ‹æ—¶ç‚¹å­˜åœ¨æ˜¾è‘—å·®å¼‚")
else:
    print("âš ï¸ å„ç»„æœ€ä½³æ£€æµ‹æ—¶ç‚¹å·®å¼‚ä¸æ˜¾è‘—")

# ==================== ç»“æœå¯è§†åŒ– ====================
print("\n8. ç»“æœå¯è§†åŒ–")
print("-" * 50)

# åˆ›å»ºè¾“å‡ºç›®å½•
import os
os.makedirs('new_results', exist_ok=True)

# åˆ›å»ºç»¼åˆå¯è§†åŒ–
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle(f'KMeansèšç±»åˆ†æç»“æœ (K={optimal_k})', fontsize=16, fontweight='bold')

# å­å›¾1: è‚˜éƒ¨æ³•æ›²çº¿
ax1 = axes[0, 0]
ax1.plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)
ax1.axvline(elbow_k, color='red', linestyle='--', alpha=0.7, label=f'è‚˜éƒ¨ç‚¹ K={elbow_k}')
ax1.axvline(optimal_k, color='green', linestyle='--', alpha=0.7, label=f'é€‰æ‹© K={optimal_k}')
ax1.set_xlabel('èšç±»æ•° K')
ax1.set_ylabel('æƒ¯æ€§ (Inertia)')
ax1.set_title('è‚˜éƒ¨æ³•ç¡®å®šæœ€ä¼˜Kå€¼')
ax1.legend()
ax1.grid(True, alpha=0.3)

# å­å›¾2: è½®å»“ç³»æ•°
ax2 = axes[0, 1]
ax2.plot(k_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)
ax2.axvline(optimal_k_silhouette, color='red', linestyle='--', alpha=0.7, 
           label=f'è½®å»“æœ€ä¼˜ K={optimal_k_silhouette}')
ax2.axvline(optimal_k, color='green', linestyle='--', alpha=0.7, label=f'é€‰æ‹© K={optimal_k}')
ax2.set_xlabel('èšç±»æ•° K')
ax2.set_ylabel('è½®å»“ç³»æ•°')
ax2.set_title('è½®å»“ç³»æ•°è¯„ä¼°')
ax2.legend()
ax2.grid(True, alpha=0.3)

# å­å›¾3: èšç±»æ•£ç‚¹å›¾
ax3 = axes[1, 0]
colors = plt.cm.tab10(np.linspace(0, 1, optimal_k))
for i in range(optimal_k):
    cluster_data = clustering_data[clustering_data['èšç±»æ ‡ç­¾'] == i]
    ax3.scatter(cluster_data['BMI'], cluster_data['è¾¾æ ‡æ—¶é—´'], 
               c=[colors[i]], label=f'ç»„{i}', s=50, alpha=0.7)

# æ·»åŠ èšç±»ä¸­å¿ƒ
centers_original = scaler.inverse_transform(kmeans_final.cluster_centers_)
ax3.scatter(centers_original[:, 0], centers_original[:, 1], 
           c='red', marker='x', s=200, linewidths=3, label='èšç±»ä¸­å¿ƒ')

ax3.set_xlabel('BMI')
ax3.set_ylabel('è¾¾æ ‡æ—¶é—´ (å‘¨)')
ax3.set_title('BMI vs è¾¾æ ‡æ—¶é—´èšç±»ç»“æœ')
ax3.legend()
ax3.grid(True, alpha=0.3)

# å­å›¾4: å„ç»„æœ€ä½³æ£€æµ‹æ—¶ç‚¹å¯¹æ¯”
ax4 = axes[1, 1]
groups = [f'ç»„{i}' for i in range(optimal_k)]
timepoints = [result['æœ€ä½³æ£€æµ‹æ—¶ç‚¹'] for result in cluster_results]
errors = [result['æ—¶ç‚¹æ ‡å‡†å·®'] for result in cluster_results]

bars = ax4.bar(groups, timepoints, yerr=errors, capsize=5, 
               color=colors[:optimal_k], alpha=0.7)

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for bar, time, err in zip(bars, timepoints, errors):
    height = bar.get_height()
    ax4.text(bar.get_x() + bar.get_width()/2., height + err + 0.2,
             f'{time:.1f}å‘¨', ha='center', va='bottom', fontweight='bold')

ax4.set_ylabel('æœ€ä½³æ£€æµ‹æ—¶ç‚¹ (å‘¨)')
ax4.set_title('å„ç»„æœ€ä½³NIPTæ£€æµ‹æ—¶ç‚¹')
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('new_results/kmeans_clustering_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# ==================== ç»“æœä¿å­˜ ====================
print("\n9. ç»“æœä¿å­˜")
print("-" * 50)

# ä¿å­˜è¯¦ç»†ç»“æœ
results_df = pd.DataFrame(cluster_results)
results_df.to_csv('new_results/kmeans_clustering_results.csv', index=False, encoding='utf-8')

# ä¿å­˜æ¯ä¸ªå­•å¦‡çš„èšç±»ä¿¡æ¯
patient_clusters = clustering_data[['å­•å¦‡ä»£ç ', 'BMI', 'è¾¾æ ‡æ—¶é—´', 'èšç±»æ ‡ç­¾']].copy()
patient_clusters.to_csv('new_results/patient_cluster_assignments.csv', index=False, encoding='utf-8')

# ä¿å­˜æ±‡æ€»ä¿¡æ¯
summary = {
    'åˆ†ææ–¹æ³•': 'KMeansäºŒç»´èšç±» (BMI + è¾¾æ ‡æ—¶é—´)',
    'æœ€ä¼˜èšç±»æ•°': int(optimal_k),
    'è‚˜éƒ¨æ³•Kå€¼': int(elbow_k),
    'è½®å»“ç³»æ•°æœ€ä¼˜Kå€¼': int(optimal_k_silhouette),
    'æœ€ç»ˆè½®å»“ç³»æ•°': float(silhouette_score(X_scaled, final_labels)),
    'æ ·æœ¬æ€»æ•°': int(len(clustering_data)),
    'BMIç»„é—´å·®å¼‚på€¼': float(p_val_bmi),
    'æ—¶ç‚¹ç»„é—´å·®å¼‚på€¼': float(p_val_time),
    'èšç±»ç»“æœ': {f'ç»„{i}': {
        'BMIåŒºé—´': result['BMIèŒƒå›´'],
        'æœ€ä½³æ—¶ç‚¹': f"{result['æœ€ä½³æ£€æµ‹æ—¶ç‚¹']:.1f}å‘¨",
        'æ ·æœ¬æ•°': int(result['æ ·æœ¬æ•°'])
    } for i, result in enumerate(cluster_results)}
}

import json
with open('new_results/kmeans_clustering_summary.json', 'w', encoding='utf-8') as f:
    json.dump(summary, f, indent=2, ensure_ascii=False)

print("âœ… ç»“æœå·²ä¿å­˜:")
print("   - new_results/kmeans_clustering_analysis.png")
print("   - new_results/kmeans_clustering_results.csv")
print("   - new_results/patient_cluster_assignments.csv")
print("   - new_results/kmeans_clustering_summary.json")

# ==================== æœ€ç»ˆç»“è®º ====================
print("\n" + "=" * 80)
print("ğŸ¯ KMeansèšç±»åˆ†ææ ¸å¿ƒç»“è®º")
print("=" * 80)
print(f"ğŸ“Š æœ€ä¼˜èšç±»æ•°: K = {optimal_k}")
print(f"ğŸ“ˆ è½®å»“ç³»æ•°: {silhouette_score(X_scaled, final_labels):.3f}")
print(f"ğŸ‘¥ åˆ†ææ ·æœ¬: {len(clustering_data)} ä¸ªå­•å¦‡")

print(f"\nğŸ” å„ç»„BMIåŒºé—´ä¸æœ€ä½³æ£€æµ‹æ—¶ç‚¹:")
for result in cluster_results:
    print(f"  {result['èšç±»ç»„']}: BMI{result['BMIèŒƒå›´']} â†’ {result['æœ€ä½³æ£€æµ‹æ—¶ç‚¹']:.1f}å‘¨ ({result['æ ·æœ¬æ•°']}äºº)")

print(f"\nğŸ“Š ç»Ÿè®¡æ˜¾è‘—æ€§:")
print(f"  BMIç»„é—´å·®å¼‚: {'æ˜¾è‘—' if p_val_bmi < 0.05 else 'ä¸æ˜¾è‘—'} (p={p_val_bmi:.6f})")
print(f"  æ—¶ç‚¹ç»„é—´å·®å¼‚: {'æ˜¾è‘—' if p_val_time < 0.05 else 'ä¸æ˜¾è‘—'} (p={p_val_time:.6f})")

print(f"\nğŸ’¡ ä¸´åºŠåº”ç”¨å»ºè®®:")
print("1. é‡‡ç”¨æ•°æ®é©±åŠ¨çš„BMIåˆ†ç»„ï¼Œæ¶ˆé™¤ä¸»è§‚æ€§")
print("2. åŸºäºäºŒç»´èšç±»(BMI+è¾¾æ ‡æ—¶é—´)çš„ä¸ªæ€§åŒ–æ£€æµ‹ç­–ç•¥")
print("3. ä¸åŒBMIç»„é‡‡ç”¨å·®å¼‚åŒ–æœ€ä½³æ£€æµ‹æ—¶ç‚¹")
print("4. å®šæœŸæ›´æ–°èšç±»æ¨¡å‹ä»¥ä¼˜åŒ–æ£€æµ‹ç­–ç•¥")
print("=" * 80)










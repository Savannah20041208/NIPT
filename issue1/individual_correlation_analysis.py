import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

print("ä¸ªä½“å†…å­•å‘¨ä¸YæŸ“è‰²ä½“æµ“åº¦ç›¸å…³æ€§åˆ†æ (Spearmanæ–¹æ³•)")
print("=" * 60)

# è¯»å–æ•°æ®
df = pd.read_csv("../new_data/boy/boy_cleaned.csv")
print(f"æ•°æ®è¯»å–å®Œæˆ: {df.shape[0]} æ¡è®°å½•ï¼Œ{df['å­•å¦‡ä»£ç '].nunique()} ä¸ªå­•å¦‡")

# ==================== ä¸ªä½“å†…ç›¸å…³æ€§è®¡ç®— ====================
print("\n1. ä¸ªä½“å†…ç›¸å…³æ€§è®¡ç®—")
print("-" * 40)

def calculate_individual_correlation(group):
    """è®¡ç®—å•ä¸ªå­•å¦‡çš„å­•å‘¨ä¸Yæµ“åº¦ç›¸å…³æ€§"""
    if len(group) < 2:  # è‡³å°‘éœ€è¦2ä¸ªæ•°æ®ç‚¹
        return np.nan
    
    # æå–å­•å‘¨å’ŒYæµ“åº¦æ•°æ®
    gestational_weeks = group['å­•å‘¨_æ•°å€¼'].values
    y_concentration = group['YæŸ“è‰²ä½“æµ“åº¦'].values
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¸¸æ•°è¾“å…¥ï¼Œé¿å…ConstantInputWarningå¯¼è‡´NaN
    if np.std(gestational_weeks) == 0 or np.std(y_concentration) == 0:
        return np.nan
    
    # è®¡ç®—Spearmanç›¸å…³ç³»æ•°ï¼ˆä¸éœ€è¦æ­£æ€åˆ†å¸ƒå‡è®¾ï¼‰
    try:
        correlation, p_value = stats.spearmanr(gestational_weeks, y_concentration)
        return correlation
    except:
        return np.nan

# è®¡ç®—æ¯ä¸ªå­•å¦‡çš„ä¸ªä½“å†…ç›¸å…³æ€§
individual_correlations = df.groupby('å­•å¦‡ä»£ç ').apply(calculate_individual_correlation)

# è¿‡æ»¤æ‰NaNå€¼ï¼ˆæ£€æµ‹æ¬¡æ•°<2çš„å­•å¦‡ï¼‰
valid_correlations = individual_correlations.dropna()

print(f"æœ‰æ•ˆä¸ªä½“å†…ç›¸å…³æ€§è®¡ç®—: {len(valid_correlations)} ä¸ªå­•å¦‡")
print(f"æ— æ•ˆæ ·æœ¬ï¼ˆæ£€æµ‹æ¬¡æ•°<2ï¼‰: {len(individual_correlations) - len(valid_correlations)} ä¸ªå­•å¦‡")

# ==================== ç»Ÿè®¡æè¿° ====================
print("\n2. ä¸ªä½“å†…ç›¸å…³æ€§ç»Ÿè®¡æè¿°")
print("-" * 40)

# åŸºæœ¬ç»Ÿè®¡
print("ä¸ªä½“å†…ç›¸å…³æ€§ç»Ÿè®¡:")
print(f"  å¹³å‡ç›¸å…³æ€§: {valid_correlations.mean():.4f}")
print(f"  ä¸­ä½æ•°ç›¸å…³æ€§: {valid_correlations.median():.4f}")
print(f"  æ ‡å‡†å·®: {valid_correlations.std():.4f}")
print(f"  æœ€å°å€¼: {valid_correlations.min():.4f}")
print(f"  æœ€å¤§å€¼: {valid_correlations.max():.4f}")

# ç›¸å…³æ€§æ–¹å‘ç»Ÿè®¡
positive_corr = (valid_correlations > 0).sum()
negative_corr = (valid_correlations < 0).sum()
zero_corr = (valid_correlations == 0).sum()

print(f"\nç›¸å…³æ€§æ–¹å‘åˆ†å¸ƒ:")
print(f"  æ­£ç›¸å…³: {positive_corr} ä¸ªå­•å¦‡ ({positive_corr/len(valid_correlations)*100:.1f}%)")
print(f"  è´Ÿç›¸å…³: {negative_corr} ä¸ªå­•å¦‡ ({negative_corr/len(valid_correlations)*100:.1f}%)")
print(f"  é›¶ç›¸å…³: {zero_corr} ä¸ªå­•å¦‡ ({zero_corr/len(valid_correlations)*100:.1f}%)")

# å¼ºç›¸å…³æ€§ç»Ÿè®¡
strong_positive = (valid_correlations > 0.7).sum()
moderate_positive = ((valid_correlations > 0.3) & (valid_correlations <= 0.7)).sum()
weak_positive = ((valid_correlations > 0) & (valid_correlations <= 0.3)).sum()

print(f"\næ­£ç›¸å…³å¼ºåº¦åˆ†å¸ƒ:")
print(f"  å¼ºæ­£ç›¸å…³ (r>0.7): {strong_positive} ä¸ªå­•å¦‡ ({strong_positive/len(valid_correlations)*100:.1f}%)")
print(f"  ä¸­ç­‰æ­£ç›¸å…³ (0.3<râ‰¤0.7): {moderate_positive} ä¸ªå­•å¦‡ ({moderate_positive/len(valid_correlations)*100:.1f}%)")
print(f"  å¼±æ­£ç›¸å…³ (0<râ‰¤0.3): {weak_positive} ä¸ªå­•å¦‡ ({weak_positive/len(valid_correlations)*100:.1f}%)")

# ==================== æ˜¾è‘—æ€§æ£€éªŒ ====================
print("\n3. ä¸ªä½“å†…ç›¸å…³æ€§çš„æ˜¾è‘—æ€§æ£€éªŒ")
print("-" * 40)

def calculate_individual_correlation_with_pvalue(group):
    """è®¡ç®—å•ä¸ªå­•å¦‡çš„ç›¸å…³æ€§åŠpå€¼"""
    if len(group) < 2:
        return pd.Series([np.nan, np.nan], index=['correlation', 'p_value'])
    
    gestational_weeks = group['å­•å‘¨_æ•°å€¼'].values
    y_concentration = group['YæŸ“è‰²ä½“æµ“åº¦'].values
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¸¸æ•°è¾“å…¥ï¼Œé¿å…ConstantInputWarningå¯¼è‡´NaN
    if np.std(gestational_weeks) == 0 or np.std(y_concentration) == 0:
        return pd.Series([np.nan, np.nan], index=['correlation', 'p_value'])
    
    try:
        correlation, p_value = stats.spearmanr(gestational_weeks, y_concentration)
        return pd.Series([correlation, p_value], index=['correlation', 'p_value'])
    except:
        return pd.Series([np.nan, np.nan], index=['correlation', 'p_value'])

# è®¡ç®—ç›¸å…³æ€§å’Œpå€¼
correlation_results = df.groupby('å­•å¦‡ä»£ç ').apply(calculate_individual_correlation_with_pvalue)
correlation_results = correlation_results.dropna()

# æ˜¾è‘—æ€§ç»Ÿè®¡
significant_positive = ((correlation_results['correlation'] > 0) & 
                       (correlation_results['p_value'] < 0.05)).sum()
significant_negative = ((correlation_results['correlation'] < 0) & 
                       (correlation_results['p_value'] < 0.05)).sum()
non_significant = (correlation_results['p_value'] >= 0.05).sum()

print(f"ä¸ªä½“å†…ç›¸å…³æ€§æ˜¾è‘—æ€§æ£€éªŒç»“æœ:")
print(f"  æ˜¾è‘—æ­£ç›¸å…³ (p<0.05): {significant_positive} ä¸ªå­•å¦‡ ({significant_positive/len(correlation_results)*100:.1f}%)")
print(f"  æ˜¾è‘—è´Ÿç›¸å…³ (p<0.05): {significant_negative} ä¸ªå­•å¦‡ ({significant_negative/len(correlation_results)*100:.1f}%)")
print(f"  ä¸æ˜¾è‘—ç›¸å…³ (pâ‰¥0.05): {non_significant} ä¸ªå­•å¦‡ ({non_significant/len(correlation_results)*100:.1f}%)")

# ==================== æ€»ä½“æ˜¾è‘—æ€§æ£€éªŒ ====================
print("\n4. æ€»ä½“ç›¸å…³æ€§æ˜¾è‘—æ€§æ£€éªŒ")
print("-" * 40)

# å¯¹å¹³å‡ç›¸å…³æ€§è¿›è¡Œtæ£€éªŒï¼ˆæ£€éªŒæ˜¯å¦æ˜¾è‘—ä¸ç­‰äº0ï¼‰
mean_correlation = valid_correlations.mean()
t_stat, t_p_value = stats.ttest_1samp(valid_correlations, 0)

print(f"æ€»ä½“ç›¸å…³æ€§æ£€éªŒç»“æœ:")
print(f"  å¹³å‡ç›¸å…³æ€§: {mean_correlation:.4f}")
print(f"  tç»Ÿè®¡é‡: {t_stat:.4f}")

# æ­£ç¡®æ˜¾ç¤ºpå€¼
if t_p_value < 1e-15:
    print(f"  på€¼: < 1e-15")
elif t_p_value < 1e-10:
    print(f"  på€¼: {t_p_value:.2e}")
else:
    print(f"  på€¼: {t_p_value:.6f}")

print(f"  æ˜¾è‘—æ€§: {'â­â­â­ é«˜åº¦æ˜¾è‘—' if t_p_value < 0.001 else 'â­â­ æ˜¾è‘—' if t_p_value < 0.05 else 'âŒ ä¸æ˜¾è‘—'}")

# 95%ç½®ä¿¡åŒºé—´
confidence_interval = stats.t.interval(0.95, len(valid_correlations)-1, 
                                      loc=mean_correlation, 
                                      scale=stats.sem(valid_correlations))
print(f"  95%ç½®ä¿¡åŒºé—´: [{confidence_interval[0]:.4f}, {confidence_interval[1]:.4f}]")

# ==================== å¯è§†åŒ–åˆ†æ ====================
print("\n5. å¯è§†åŒ–åˆ†æ")
print("-" * 40)

# åˆ›å»º2x2å­å›¾
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle('ä¸ªä½“å†…å­•å‘¨-YæŸ“è‰²ä½“æµ“åº¦ç›¸å…³æ€§åˆ†æ', fontsize=16)

# 1. ç›¸å…³ç³»æ•°åˆ†å¸ƒç›´æ–¹å›¾
axes[0,0].hist(valid_correlations, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
axes[0,0].axvline(mean_correlation, color='red', linestyle='--', 
                  label=f'å‡å€¼: {mean_correlation:.3f}')
axes[0,0].set_xlabel('Spearmanç›¸å…³ç³»æ•°')
axes[0,0].set_ylabel('é¢‘æ•°')
axes[0,0].set_title('ä¸ªä½“å†…ç›¸å…³æ€§åˆ†å¸ƒ')
axes[0,0].legend()
axes[0,0].grid(True, alpha=0.3)

# 2. Q-Qå›¾æ£€éªŒæ­£æ€æ€§
stats.probplot(valid_correlations, dist="norm", plot=axes[0,1])
axes[0,1].set_title('ç›¸å…³ç³»æ•°æ­£æ€æ€§æ£€éªŒ')
axes[0,1].grid(True, alpha=0.3)

# 3. ç›¸å…³æ€§å¼ºåº¦åˆ†ç±»æŸ±çŠ¶å›¾
categories = ['å¼ºæ­£ç›¸å…³\n(r>0.7)', 'ä¸­ç­‰æ­£ç›¸å…³\n(0.3<râ‰¤0.7)', 'å¼±æ­£ç›¸å…³\n(0<râ‰¤0.3)', 
              'è´Ÿç›¸å…³\n(râ‰¤0)']
counts = [strong_positive, moderate_positive, weak_positive, negative_corr]
colors = ['darkgreen', 'green', 'lightgreen', 'red']

bars = axes[1,0].bar(categories, counts, color=colors, alpha=0.7)
axes[1,0].set_ylabel('å­•å¦‡æ•°é‡')
axes[1,0].set_title('ç›¸å…³æ€§å¼ºåº¦åˆ†ç±»')
axes[1,0].tick_params(axis='x', rotation=45)

# åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
for bar, count in zip(bars, counts):
    height = bar.get_height()
    axes[1,0].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                   f'{count}', ha='center', va='bottom')

# 4. ç®±çº¿å›¾
axes[1,1].boxplot(valid_correlations, tick_labels=['ä¸ªä½“å†…ç›¸å…³æ€§'])
axes[1,1].set_ylabel('Spearmanç›¸å…³ç³»æ•°')
axes[1,1].set_title('ç›¸å…³æ€§åˆ†å¸ƒç®±çº¿å›¾')
axes[1,1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('new_results/individual_correlation_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# ==================== ä¸æ€»ä½“ç›¸å…³æ€§å¯¹æ¯” ====================
print("\n6. ä¸æ€»ä½“ç›¸å…³æ€§å¯¹æ¯”")
print("-" * 40)

# è®¡ç®—æ€»ä½“ç›¸å…³æ€§ï¼ˆæ‰€æœ‰æ•°æ®æ··åˆï¼‰
# å…ˆåˆ é™¤ä»»ä¸€åˆ—ä¸ºç©ºçš„è¡Œï¼Œç¡®ä¿æ•°ç»„é•¿åº¦ä¸€è‡´
valid_data = df[['å­•å‘¨_æ•°å€¼', 'YæŸ“è‰²ä½“æµ“åº¦']].dropna()
overall_correlation, overall_p = stats.spearmanr(valid_data['å­•å‘¨_æ•°å€¼'], 
                                                valid_data['YæŸ“è‰²ä½“æµ“åº¦'])

print(f"ç›¸å…³æ€§å¯¹æ¯”:")
print(f"  ä¸ªä½“å†…å¹³å‡ç›¸å…³æ€§: {mean_correlation:.4f} (p = {'< 1e-15' if t_p_value < 1e-15 else f'{t_p_value:.6f}'})")
print(f"  æ€»ä½“æ··åˆç›¸å…³æ€§: {overall_correlation:.4f} (p = {overall_p:.6f})")
print(f"  å·®å¼‚: {mean_correlation - overall_correlation:.4f}")
print(f"âœ… ä¸ªä½“å†…ç›¸å…³æ€§æ›´å¼ºï¼Œè¯´æ˜æ§åˆ¶ä¸ªä½“å·®å¼‚å¾ˆé‡è¦")

# ==================== ä¿å­˜åˆ†æç»“æœ ====================
print("\n7. ä¿å­˜åˆ†æç»“æœ")
print("-" * 40)

# ä¿å­˜ä¸ªä½“ç›¸å…³æ€§ç»“æœ
individual_results_df = pd.DataFrame({
    'å­•å¦‡ä»£ç ': valid_correlations.index,
    'ä¸ªä½“å†…ç›¸å…³æ€§': valid_correlations.values
})

import os
os.makedirs('new_results', exist_ok=True)
individual_results_df.to_csv('new_results/individual_correlations.csv', index=False, encoding='utf-8')
print("âœ… ä¸ªä½“ç›¸å…³æ€§ç»“æœå·²ä¿å­˜: new_results/individual_correlations.csv")

# ä¿å­˜æ±‡æ€»ç»“æœ
summary_results = {
    'å¹³å‡ä¸ªä½“å†…ç›¸å…³æ€§': mean_correlation,
    'ç›¸å…³æ€§æ ‡å‡†å·®': valid_correlations.std(),
    'ç›¸å…³æ€§ä¸­ä½æ•°': valid_correlations.median(),
    'æœ‰æ•ˆæ ·æœ¬æ•°': len(valid_correlations),
    'tç»Ÿè®¡é‡': t_stat,
    'på€¼': t_p_value,
    '95%ç½®ä¿¡åŒºé—´ä¸‹é™': confidence_interval[0],
    '95%ç½®ä¿¡åŒºé—´ä¸Šé™': confidence_interval[1],
    'æ€»ä½“æ··åˆç›¸å…³æ€§': overall_correlation,
    'æ€»ä½“æ··åˆpå€¼': overall_p,
    'æ­£ç›¸å…³æ¯”ä¾‹': positive_corr/len(valid_correlations),
    'æ˜¾è‘—æ­£ç›¸å…³æ¯”ä¾‹': significant_positive/len(correlation_results)
}

import json
with open('new_results/correlation_summary.json', 'w', encoding='utf-8') as f:
    json.dump(summary_results, f, indent=2, ensure_ascii=False)
print("âœ… æ±‡æ€»ç»“æœå·²ä¿å­˜: new_results/correlation_summary.json")

print("âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: new_results/individual_correlation_analysis.png")

print("=" * 60)
print("ğŸ¯ æ ¸å¿ƒç»“è®º:")
print(f"ğŸ“Š ä¸ªä½“å†…å¹³å‡ç›¸å…³æ€§: {mean_correlation:.4f}")
print(f"ğŸ“ˆ ç»Ÿè®¡æ˜¾è‘—æ€§: p = {'< 1e-15' if t_p_value < 1e-15 else f'{t_p_value:.6f}'}")
print(f"ğŸ‘¥ æœ‰æ•ˆæ ·æœ¬: {len(valid_correlations)} ä¸ªå­•å¦‡")
print(f"âœ… æ­£ç›¸å…³æ¯”ä¾‹: {positive_corr/len(valid_correlations)*100:.1f}%")
print("=" * 60)
